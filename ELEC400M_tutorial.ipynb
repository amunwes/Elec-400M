{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amunwes/Elec-400M/blob/main/ELEC400M_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I Google Colab"
      ],
      "metadata": {
        "id": "_4MkGjY-zRAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Colab?**\n",
        "Colab, or \"Colaboratory\", allows you to write and execute Python in your browser, with\n",
        "\n",
        "\n",
        "\n",
        "*   Zero configuration required\n",
        "*   Free access to GPUs\n",
        "*   Easy sharing\n",
        "\n",
        "\n",
        "\n",
        "[Google Colaboratory](https://colab.research.google.com/?utm_source=scs-index#)\n",
        "\n",
        "[Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI&ab_channel=TensorFlow)"
      ],
      "metadata": {
        "id": "rQEJ3WW642Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The reasons** we suggest using Colab for the assignments/projects in this class is because:\n",
        "\n",
        "1.   We will use Python as our main programming language for the class, and Google Colab is like Google Drive of Jupyter Notebook that you can easily share with your teammates.\n",
        "2.   When it comes to Deep Learning, you may need GPUs to accelerate your trainings to catch up with the deadlines, and Google Colab provides free GPU computing resources.\n",
        "3.   You DON'T need to install Python library packages one by one to start your job.\n",
        "4.   (tips) Each Google account can launch 2 running tasks in Colab, so if you have more Google accounts, you can run multiple training at the same time.\n",
        "5.   (tips) Remember to save your output files before closing the website/tab.\n",
        "\n"
      ],
      "metadata": {
        "id": "ED9AXB2L5tGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:**\n",
        "\n",
        "Calculate the inner product of a=[1, 1, 1, 1, 1, 1] and b=[1, 0, -1, 1, 0, -1]."
      ],
      "metadata": {
        "id": "lRGKZBU-98Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 1, 1, 1, 1, 1] )\n",
        "b = np.array([1, 0, -1, 1, 0, -1])\n",
        "np.dot(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwE40mZP-XS7",
        "outputId": "72889064-625e-4a37-cff8-ded3fa400c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II Scikit-Learn"
      ],
      "metadata": {
        "id": "BMyPD0Iw_Kha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Scikit-Learn?**\n",
        "Scikit-Learn, or sklearn, is an useful Python package which is\n",
        "\n",
        "\n",
        "*   Simple and efficient tools for predictive data analysis\n",
        "*   Accessible to everybody, and reusable in various contexts\n",
        "*   Built on NumPy, SciPy, and matplotlib\n",
        "*   Open source, commercially usable - BSD license\n",
        "\n",
        "In general, Scikit-Learn is a convenient package to do Machine Learning tasks, and it can integrate with other useful packages.  \n",
        "\n",
        "[Scikit-Learn](https://scikit-learn.org/stable/)\n",
        "\n"
      ],
      "metadata": {
        "id": "lrbroEvxA5x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:**\n",
        "\n",
        "Fit a 2-D Linear Regression line to predict the relationship between *Years of Working Experience(X)* and *Salary You Can Earn(y)*.\n",
        "\n",
        "$y = w_1*X + w_0$\n"
      ],
      "metadata": {
        "id": "286IFz2PGR5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv6Y6MsnVkfP"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "# reading/dealing with csv files\n",
        "import pandas as pd\n",
        "# loading ML algorithms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the data csv\n",
        "dataset = pd.read_csv('linear_regression_ex.csv')\n",
        "dataset.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "xllbu4fVZ3zs",
        "outputId": "bc825320-5ad3-432d-8d1b-90e9482a20dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       experience        salary\n",
              "count   20.000000     20.000000\n",
              "mean     8.025000  10450.000000\n",
              "std      6.131186   6607.153221\n",
              "min      0.000000   2250.000000\n",
              "25%      2.750000   5375.000000\n",
              "50%      7.500000   8600.000000\n",
              "75%     12.250000  15000.000000\n",
              "max     20.000000  23000.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-580245ab-ab5e-46e3-a70e-d37c3e50b555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experience</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.025000</td>\n",
              "      <td>10450.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.131186</td>\n",
              "      <td>6607.153221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.750000</td>\n",
              "      <td>5375.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>8600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.250000</td>\n",
              "      <td>15000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>23000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-580245ab-ab5e-46e3-a70e-d37c3e50b555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-580245ab-ab5e-46e3-a70e-d37c3e50b555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-580245ab-ab5e-46e3-a70e-d37c3e50b555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot out the data distribution\n",
        "dataset.plot(x='experience', y='salary', style='o')\n",
        "plt.title('Years of Experience v.s. Salary per Month')\n",
        "plt.xlabel('Years of Experience(yrs)')\n",
        "plt.ylabel('Salary per Month(CAD)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vMM0V3y9d-Ll",
        "outputId": "eae23281-4ed2-4e7f-de2a-38a4c5fbc2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pull out the data of interest\n",
        "X = dataset['experience'].values.reshape(-1, 1) # sklearn requires 2-D array as inputs\n",
        "y = dataset['salary'].values.reshape(-1, 1)\n",
        "\n",
        "# split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "NNqK5YO_i1CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize linear regression class and fit the model with training data\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsNbBHhslr6A",
        "outputId": "da8a8044-d81f-4818-d6bd-f8c168313ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the result w0 and w1\n",
        "w_0 = regressor.intercept_\n",
        "w_1 = regressor.coef_\n",
        "\n",
        "print('Interception : ', w_0)\n",
        "print('Coeficient : ', w_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geVRYV5Dl4ZS",
        "outputId": "65cbf26e-64e4-42a1-a151-cf88a777623d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interception :  [1965.45757293]\n",
            "Coeficient :  [[1069.05821234]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict y\n",
        "y_pred = regressor.predict(X_test)\n",
        "print('Predict : ', y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9ybBnRmpfq",
        "outputId": "9f8592ef-84d2-49e6-82af-c33407bc9c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict :  [[12656.03969628]\n",
            " [ 1965.45757293]\n",
            " [11586.98148395]\n",
            " [ 3034.51578527]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the results in a table\n",
        "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "pcoi9zDlmuTX",
        "outputId": "b9a10a83-6ed4-47ff-9d2a-766280c0a59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Actual     Predicted\n",
              "0   13000  12656.039696\n",
              "1    2250   1965.457573\n",
              "2    8700  11586.981484\n",
              "3    3400   3034.515785"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7fe76f8-547a-4cfb-b965-541d75cb8796\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13000</td>\n",
              "      <td>12656.039696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2250</td>\n",
              "      <td>1965.457573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8700</td>\n",
              "      <td>11586.981484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3400</td>\n",
              "      <td>3034.515785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7fe76f8-547a-4cfb-b965-541d75cb8796')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7fe76f8-547a-4cfb-b965-541d75cb8796 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7fe76f8-547a-4cfb-b965-541d75cb8796');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the results in a graph\n",
        "plt.scatter(X_test, y_test,  color='gray', label='Actual')\n",
        "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tbP0GmL3mydx",
        "outputId": "05ef07c3-5e6a-4f9e-83f6-ba80ab30369c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Errors of your prediction\n",
        "import numpy as np\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDr-DvKzm_m6",
        "outputId": "ff0800c2-b155-4cd6-bf3b-198c7db92f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 970.2421073664582\n",
            "Mean Squared Error: 2166878.4708034773\n",
            "Root Mean Squared Error: 1472.0320889177237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A better evaluation of your prediction (R^2)\n",
        "score = regressor.score(X_test, y_test)\n",
        "print('Score: ', score)\n",
        "print('Accuracy: ' + str(score*100) + '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIZpcS1GnNIx",
        "outputId": "0f225104-26d7-49b1-8dcf-322d10810a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score:  0.8833551554521178\n",
            "Accuracy: 88.33551554521179%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Scikit-Learn score ref](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score)"
      ],
      "metadata": {
        "id": "rK2zV2_-JSe2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1xltOtBJYat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART III **PyTorch**"
      ],
      "metadata": {
        "id": "lRAAltsOoyoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is one of the most popular open-source Deep Learning frameworks developed and maintained by **Meta (Facebook)**. It is very popular among researchers and developers as it provides fast and flexible implementations and seamless transaction to production deployments. Here are some basic concepts about PyTorch\n",
        "\n",
        "\n",
        "*   PyTorch defines a datatype - Tensor, which is very similar to NumPy Array. This allows us to easily operate on array/matrix-like inputs.\n",
        "*   PyTorch Tensors can automatically track the gradients which is useful in gradient decent/back propagation -- very useful when training a deep learning model.\n",
        "*   PyTorch has many built-in training algorithms and famous models such as Adam optimizer and ResNet series.\n",
        "*   For more details, please refer to this tutorial https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html or their official website https://pytorch.org/.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vmDLXiDoqHFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will introduce some basic usage of PyTorch Tensor in this part.\n",
        "\n"
      ],
      "metadata": {
        "id": "RGurR9dSpfZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. PyTorch Tensors (Tensor) and NumPy Arrays (Array) share similar initializations and are interchangable to each other."
      ],
      "metadata": {
        "id": "q6AwwYw0zmfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print('---------- NumPy Array and PyTorch Tensor conversion ----------')\n",
        "# We can initialize Tensor and Array in similar ways\n",
        "print('Initialization:')\n",
        "a = np.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]])\n",
        "b = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]])\n",
        "print(f'a(numpy)={a}')\n",
        "print(f'b(tensor)={b}')\n",
        "print()\n",
        "\n",
        "# We can directly convert between Array and Tensor\n",
        "print('Conversion:')\n",
        "a_tensor = torch.from_numpy(a)\n",
        "b_numpy = np.array(b)\n",
        "print(f'a(tensor)={a_tensor}')\n",
        "print(f'b(numpy)={b_numpy}')\n",
        "print()\n",
        "\n",
        "print('---------- NumPy Array and PyTorch Tensor initialization ----------')\n",
        "# The ways to initialize an all-0, all-1, random arrays are similar\n",
        "shape = (2, 2, 3)\n",
        "\n",
        "# Initialize NumPy Arrays\n",
        "print('Special initialization -- NumPy')\n",
        "a0_numpy = np.zeros(shape)\n",
        "a1_numpy = np.ones(shape)\n",
        "rand_numpy = np.random.randn(shape[0], shape[1], shape[2])\n",
        "print(f'0s(numpy)={a0_numpy}')\n",
        "print(f'1s(numpy)={a1_numpy}')\n",
        "print(f'random(numpy)={rand_numpy}')\n",
        "print()\n",
        "\n",
        "# Initialize PyTorch Tensors\n",
        "print('Special initialization -- PyTorch')\n",
        "a0_tensor = torch.zeros(shape)\n",
        "a1_tensor = torch.ones(shape)\n",
        "rand_tensor = torch.randn(shape)\n",
        "print(f'0s(tensor)={a0_tensor}')\n",
        "print(f'1s(tensor)={a1_tensor}')\n",
        "print(f'random(tensor)={rand_tensor}')\n",
        "print()"
      ],
      "metadata": {
        "id": "xpoYtXz4z4bV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90586b6-2a32-4cc6-8850-fb5c0b20ce5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- NumPy Array and PyTorch Tensor conversion ----------\n",
            "Initialization:\n",
            "a(numpy)=[[[1 2 3]\n",
            "  [4 5 6]]\n",
            "\n",
            " [[1 2 3]\n",
            "  [4 5 6]]]\n",
            "b(tensor)=tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]],\n",
            "\n",
            "        [[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "\n",
            "Conversion:\n",
            "a(tensor)=tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]],\n",
            "\n",
            "        [[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "b(numpy)=[[[1 2 3]\n",
            "  [4 5 6]]\n",
            "\n",
            " [[1 2 3]\n",
            "  [4 5 6]]]\n",
            "\n",
            "---------- NumPy Array and PyTorch Tensor initialization ----------\n",
            "Special initialization -- NumPy\n",
            "0s(numpy)=[[[0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]]]\n",
            "1s(numpy)=[[[1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]]]\n",
            "random(numpy)=[[[-0.50163224 -0.06926081 -1.33115862]\n",
            "  [ 1.40406114  0.10918661  0.26670177]]\n",
            "\n",
            " [[ 0.316651   -0.82542648  0.5737989 ]\n",
            "  [ 0.51291782  0.00463353  0.0819398 ]]]\n",
            "\n",
            "Special initialization -- PyTorch\n",
            "0s(tensor)=tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "1s(tensor)=tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "random(tensor)=tensor([[[-0.0990,  0.6610, -0.9244],\n",
            "         [ 1.0337,  2.9532,  1.2278]],\n",
            "\n",
            "        [[ 0.0049,  0.5101, -1.8807],\n",
            "         [-1.8407,  0.0088, -0.3355]]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. PyTorch Tensor matrix operations"
      ],
      "metadata": {
        "id": "Ex2NA5ue35xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix operations - add, subtract, multiply, divide, concatenate\n",
        "a = torch.ones((3, 3))\n",
        "b = 2*torch.ones((3, 3))\n",
        "print(f'a={a}')\n",
        "print(f'b={b}')\n",
        "print()\n",
        "\n",
        "print('---------- Add ----------')\n",
        "print(a+b)\n",
        "print()\n",
        "\n",
        "print('---------- Substract ----------')\n",
        "print(a-b)\n",
        "print()\n",
        "\n",
        "print('---------- Multiply ----------')\n",
        "print(a.mul(b)) # element-wise multiplication, same as a*b\n",
        "print(a.matmul(b)) # matrix multiplicaton\n",
        "print()\n",
        "\n",
        "print('---------- Divide ----------')\n",
        "print(a/b) # element-wise division\n",
        "print(torch.div(a, b)) # element-wise division\n",
        "print()\n",
        "\n",
        "print('---------- Concatenate ----------')\n",
        "print(torch.cat([a, b], dim=0)) # through dim 0\n",
        "print(torch.cat([a, b], dim=1)) # through dim 1\n",
        "print()"
      ],
      "metadata": {
        "id": "gzDW0tbL2RY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86505ef-e5f3-4c5d-c8be-089cf99aafbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "b=tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "\n",
            "---------- Add ----------\n",
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n",
            "\n",
            "---------- Substract ----------\n",
            "tensor([[-1., -1., -1.],\n",
            "        [-1., -1., -1.],\n",
            "        [-1., -1., -1.]])\n",
            "\n",
            "---------- Multiply ----------\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]])\n",
            "\n",
            "---------- Divide ----------\n",
            "tensor([[0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000]])\n",
            "tensor([[0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000]])\n",
            "\n",
            "---------- Concatenate ----------\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[1., 1., 1., 2., 2., 2.],\n",
            "        [1., 1., 1., 2., 2., 2.],\n",
            "        [1., 1., 1., 2., 2., 2.]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P3uPIYli7hS6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "c1404257-f8ff-4dba-e8f6-eaa2135c66b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 120\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How to compute gradient in PyTorch? **torch.autograd!**\n",
        "\n",
        "torch.autograd is PyTorchs automatic differentiation engine that powers neural network training.\n",
        "We only need to call target.backward() to find the corresponding gradients.\n",
        "\n",
        "We show a simple example here:\n",
        "\n",
        "Given an equation $Q = 3a^3 - b^2$.\n",
        "We want to find the gradient of $Q$ w.r.t. $a$ and $b$, $\\frac{\\partial Q}{\\partial a} = 9a^2$ and $\\frac{\\partial Q}{\\partial b} = -2b$.\n"
      ],
      "metadata": {
        "id": "dUQG074p8r4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tensors\n",
        "a = torch.tensor([2., 3.])\n",
        "b = torch.tensor([6., 4.])\n",
        "\n",
        "# Q = 3a^3 - b^2\n",
        "Q = 3*a**3 - b**2\n",
        "\n",
        "# Note that in back propagation, we need to know Q's gradient first to further calculate the gradients backwards.\n",
        "# Since here Q is our target and IT IS A VECTOR, so we simply need to assign [1, 1] to it (dQ/dQ = 1)\n",
        "Q_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=Q_grad)\n",
        "\n",
        "# Now we can check the gradients of a and be by calling a.grad and b.grad, respectively\n",
        "print(f'Q = {Q}')\n",
        "print(f'a = {a}')\n",
        "print(f'b = {b}')\n",
        "print(f'dQ/da = {a.grad}')\n",
        "print(f'9a^2 = {9*a**2}')\n",
        "print(f'dQ/db = {b.grad}!')\n",
        "print(f'-2b = {-2*b}')"
      ],
      "metadata": {
        "id": "9FKri7kW-p6i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "be38f051-24a9-4a9d-b0e5-8e11fe756c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-128919f9d9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Since here Q is our target and IT IS A VECTOR, so we simply need to assign [1, 1] to it (dQ/dQ = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mQ_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Now we can check the gradients of a and be by calling a.grad and b.grad, respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's wrong?\n",
        "We need to initialize tensors with flag 'requires_grad' so that PyTorch knows the tensor needs tracking the gradients!\n",
        "After seeting up, PyTorch will automatically compute and store the gradients for us.\n"
      ],
      "metadata": {
        "id": "acH7s5Qa4NMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tensors with flag 'requires_grad=True'\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "\n",
        "# Q = 3a^3 - b^2\n",
        "Q = 3*a**3 - b**2\n",
        "\n",
        "# Note that in back propagation, we need to know Q's gradient first to further calculate the gradients backwards.\n",
        "# Since here Q is our target and IT IS A VECTOR, so we simply need to assign [1, 1] to it (dQ/dQ = 1)\n",
        "Q_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=Q_grad)\n",
        "\n",
        "# Now we can check the gradients of a and be by calling a.grad and b.grad, respectively\n",
        "print(f'Q = {Q}')\n",
        "print(f'a = {a}')\n",
        "print(f'b = {b}')\n",
        "print(f'dQ/da = {a.grad}')\n",
        "print(f'9a^2 = {9*a**2}')\n",
        "print(f'dQ/db = {b.grad}!')\n",
        "print(f'-2b = {-2*b}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUR0pR0z5Daw",
        "outputId": "8a570bf2-0c52-4fbc-d8cf-584cfed0d854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q = tensor([-12.,  65.], grad_fn=<SubBackward0>)\n",
            "a = tensor([2., 3.], requires_grad=True)\n",
            "b = tensor([6., 4.], requires_grad=True)\n",
            "dQ/da = tensor([36., 81.])\n",
            "9a^2 = tensor([36., 81.], grad_fn=<MulBackward0>)\n",
            "dQ/db = tensor([-12.,  -8.])!\n",
            "-2b = tensor([-12.,  -8.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One thing to notice is that, if the variable we're going to call \".backward()\" on is a scalar (say our loss), We don't need to provide any input. For example:"
      ],
      "metadata": {
        "id": "x0JS3ezzAy4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tensors with flag 'requires_grad=True'\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "\n",
        "# Q = a*b^T\n",
        "Q = a.matmul(b.T)\n",
        "\n",
        "# Now do Q.backward()\n",
        "Q.backward()\n",
        "\n",
        "# Now we can check the gradients of a and be by calling a.grad and b.grad, respectively\n",
        "print(f'dQ/da = {a.grad}')\n",
        "print(f'b.T = {b.T}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3ujq4kxH9WM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3fea42-10e6-48ac-f84a-aec643a0ad31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dQ/da = tensor([6., 4.])\n",
            "b.T = tensor([6., 4.], grad_fn=<PermuteBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a deep learning framework with PyTorch"
      ],
      "metadata": {
        "id": "wM8sC4_3rF0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Typically, training a deep learning framework with PyTorch contains\n",
        "\n",
        " 1.   Set up the way you want to load your data (TensorDataset, DataLoader)\n",
        " 2.   Define the DL network you want to use (nn.Module)\n",
        " 3.   Define training strategies (loss function, optimizer)\n",
        " 4.   Integrate your train steps, and report loss and accuracy for each step\n",
        " 5.   Summerize training results (loss, accuracy, time)\n"
      ],
      "metadata": {
        "id": "ANybcHUGqE2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Set up the way you want to load your data\n",
        "In your HW4, you will use TensorDataset and DataLoader to manage your input.\n",
        "\n",
        "**TensorDataset:**\n",
        "The class helps you **read your input data into PyTorch system**. It takes (data, label) as input, the 1st dimension of data and label should match.\n",
        "\n",
        "**DataLoader:**\n",
        "The class helps you **define the way to load the tensor inputs into training**. It defines some hyperparameters such as batch size and whether to shuffle data or not, and takes PyTorch Dataset class as input.\n"
      ],
      "metadata": {
        "id": "rBAGIfnUwLCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# make sure you have gpu available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "# make the results are reproducable\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "# Let's first define random image inputs.\n",
        "def init_toy_data(dim):\n",
        "    np.random.seed(0)\n",
        "    X = 10 * np.random.randn(dim[0], dim[1], dim[2], dim[3])\n",
        "    y = np.random.randint(low=0, high=3, size=dim[0])\n",
        "    return X, y\n",
        "\n",
        "# Define our training and validation data\n",
        "# Notice that the dimensions of a batch image input follows (batch, channel, H, W)\n",
        "train_dim = (100, 3, 32, 32)\n",
        "train_X, train_y = init_toy_data(train_dim)\n",
        "val_dim = (100, 3, 32, 32)\n",
        "val_X, val_y = init_toy_data(val_dim)\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(val_X.shape)\n",
        "print(val_y.shape)"
      ],
      "metadata": {
        "id": "pi92Ok_qm59o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635251f6-e849-452f-b10a-b6eace80ede9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "(100, 3, 32, 32)\n",
            "(100,)\n",
            "(100, 3, 32, 32)\n",
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# Load data into PyTorch dataset\n",
        "train_dataset = TensorDataset(torch.from_numpy(train_X).float(), torch.from_numpy(train_y).to(torch.long))\n",
        "val_dataset = TensorDataset(torch.from_numpy(val_X).float(), torch.from_numpy(val_y).to(torch.long))\n",
        "\n",
        "# Load PyTorch dataset into DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2) # shuffle trainset for better stochastic result\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "0HfjYtq02jqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Define the DL network you want to use\n",
        "\n",
        "We use nn.Module as the parent(base) class to define our network in PyTorch.\n",
        "\n",
        "We will introduce Multi Layer Perceptron (MLP) and Convolutional Neural Network (CNN) in this tutorial.\n",
        "\n",
        "\n",
        "\n",
        "**MLP: torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None);**\n",
        "The layer expects input of shape (batch_size, in_features) and will produce output of shape (batch_size, out_features).\n",
        "\n",
        "**CNN: torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None);**\n",
        "The layer expects input of shape (batch_size, in_channels, H_in, W_in) and will produce output of different shapes according to the hyperparameter design.\n",
        "\n",
        "For more details, please refer to https://pytorch.org/docs/stable/generated/torch.nn.Linear.html and https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html.\n"
      ],
      "metadata": {
        "id": "MH7yHPvJ43FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# define a simple MLP model.\n",
        "class toy_linear_model(nn.Module):\n",
        "    def __init__(self, input_d, hidden_d, output_d):\n",
        "        super().__init__()\n",
        "\n",
        "        # define 2 linear layers\n",
        "        self.linear0 = nn.Linear(input_d, hidden_d)\n",
        "        self.linear1 = nn.Linear(hidden_d, output_d)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Flatten the input\n",
        "        # 3,32*,32 -> 1,3*32*32\n",
        "        output = torch.flatten(x, 1)\n",
        "\n",
        "        output = self.linear0(output)\n",
        "        output = self.linear1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# define a simple CNN model. Note we assume our input has shape (batch, 3, 32, 32) as CIFAR10 images.\n",
        "class toy_cnn_model(nn.Module):\n",
        "    def __init__(self, channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # define 2 convolutional layers\n",
        "        self.conv0 = nn.Conv2d(channels[0], channels[1], kernel_size=3)\n",
        "        self.conv1 = nn.Conv2d(channels[1], channels[2], kernel_size=3)\n",
        "\n",
        "        # define linear layers to project\n",
        "        self.linear0 = nn.Linear(28*28*channels[2], 1024)\n",
        "        self.linear1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output = self.conv0(x)\n",
        "        output = self.conv1(output)\n",
        "\n",
        "        # flatten the feature map except the batch dim\n",
        "        output = torch.flatten(output, 1)\n",
        "\n",
        "        output = self.linear0(output)\n",
        "        output = self.linear1(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "v2BgGiZ44WTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define MLP model and CNN model, and put them into GPU\n",
        "MLP_model = toy_linear_model(3*32*32, 1024, 3).to(device)\n",
        "CNN_model = toy_cnn_model([3, 16, 32], 3).to(device)\n",
        "print(MLP_model)\n",
        "print(CNN_model)"
      ],
      "metadata": {
        "id": "IRim3fu2BgR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe49c59-dff2-48fd-893d-261692d0cb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toy_linear_model(\n",
            "  (linear0): Linear(in_features=3072, out_features=1024, bias=True)\n",
            "  (linear1): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n",
            "toy_cnn_model(\n",
            "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (linear0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "  (linear1): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Define training strategies\n",
        "\n",
        "We will define the strategies we want to apply to our DL training.\n",
        "\n",
        "**Loss function:**\n",
        "PyTorch provides several loss functions. We will use Cross Entropy Loss for our classification model. Please refer to https://pytorch.org/docs/stable/nn.html#loss-functions for more options.\n",
        "\n",
        "**Optimizer:**\n",
        "PyTorch provides several optimizer algorithms. Here we use Adam as our optimizer. Please refer to https://pytorch.org/docs/stable/optim.html for more options.\n",
        "\n"
      ],
      "metadata": {
        "id": "0rSQNBxd_9Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cross entropy loss function as criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define 2 Adam optimizers for our MLP and CNN models\n",
        "optimizer_MLP = torch.optim.Adam(MLP_model.parameters())\n",
        "optimizer_CNN = torch.optim.Adam(CNN_model.parameters())"
      ],
      "metadata": {
        "id": "WYwDnp-F_3Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Integrate your train steps, and report loss and accuracy for each step\n",
        "\n",
        "Here we will define two functions, train_model and val_model. The train_model function is expected to execute forward pass, backward propagation, optimizing learning rate, and reporting training loss and accuracy. The val_model function is expected to do forward pass and reports validation loss and accuracy."
      ],
      "metadata": {
        "id": "ZhiDYBnJDSHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, model, optimizer, criterion):\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    # set model to training mode so that it computes things that are needed to update the loss\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # put our inputs into GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # clear gradients in optimizer before back propagation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # feed images into model and fine the predicted output\n",
        "        outputs = model(images)\n",
        "\n",
        "        # compute loss and back propagation\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track train loss by multiplying average loss by number of examples in batch\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate accuracy by finding max log probability\n",
        "        _, pred = torch.max(outputs, dim=1)\n",
        "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "\n",
        "        # Need to convert correct tensor from int to float to average\n",
        "        accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "\n",
        "        # Multiply average accuracy times the number of examples in batch\n",
        "        train_acc += accuracy.item() * images.size(0)\n",
        "\n",
        "    # average loss and accuracy\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def val_model(val_loader, model, criterion):\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "\n",
        "    # set model to validation mode so that it DOESN'T computes things that are needed to update the loss\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for i, (images, labels) in enumerate(val_loader):\n",
        "\n",
        "            # put our inputs into GPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # feed images into model and fine the predicted output\n",
        "            outputs = model(images)\n",
        "\n",
        "            # compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track validation loss by multiplying average loss by number of examples in batch\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max log probability\n",
        "            _, pred = torch.max(outputs, dim=1)\n",
        "            correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            val_acc += accuracy.item() * images.size(0)\n",
        "\n",
        "        # average loss and accuracy\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_acc / len(val_loader.dataset)\n",
        "\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "mLdOm8rODQAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Summerize training results\n",
        "\n",
        "Here we begin training our MLP model. We will summarize the loss, accuracy and time."
      ],
      "metadata": {
        "id": "BMuQ8n7AKCrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# train MLP\n",
        "start_time = time.time()\n",
        "print('-----------------------Train MLP-------------------------')\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss, train_acc = train_model(train_loader, MLP_model, optimizer_MLP, criterion)\n",
        "    val_loss, val_acc = val_model(val_loader, MLP_model, criterion)\n",
        "    print(f'Epoch: {epoch}')\n",
        "    print(f'  Training Loss: {train_loss}, Training Accuracy: {train_acc}')\n",
        "    print(f'  Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
        "\n",
        "print(f'Elapsed time for MLP model: {(time.time()-start_time)/60} mins')\n",
        "\n",
        "# train CNN\n",
        "start_time = time.time()\n",
        "print('-----------------------Train CNN-------------------------')\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss, train_acc = train_model(train_loader, CNN_model, optimizer_CNN, criterion)\n",
        "    val_loss, val_acc = val_model(val_loader, CNN_model, criterion)\n",
        "    print(f'Epoch: {epoch}')\n",
        "    print(f'  Training Loss: {train_loss}, Training Accuracy: {train_acc}')\n",
        "    print(f'  Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
        "\n",
        "print(f'Elapsed time for CNN model: {(time.time()-start_time)/60} mins')\n"
      ],
      "metadata": {
        "id": "0HKth9UXKY2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385e6c6f-d429-4702-e17b-3b15a984dcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------Train MLP-------------------------\n",
            "Epoch: 1\n",
            "  Training Loss: 12.48176155090332, Training Accuracy: 0.3200000040233135\n",
            "  Validation Loss: 0.7361721106906771, Validation Accuracy: 0.9399999916553498\n",
            "Epoch: 2\n",
            "  Training Loss: 0.7845265764952635, Training Accuracy: 0.9600000023841858\n",
            "  Validation Loss: 0.03694667995220868, Validation Accuracy: 0.9899999976158143\n",
            "Epoch: 3\n",
            "  Training Loss: 0.07953918590443046, Training Accuracy: 0.9899999976158143\n",
            "  Validation Loss: 8.92944893276848e-05, Validation Accuracy: 1.0\n",
            "Epoch: 4\n",
            "  Training Loss: 0.0003920087864969446, Training Accuracy: 1.0\n",
            "  Validation Loss: 0.0008239072933655222, Validation Accuracy: 1.0\n",
            "Epoch: 5\n",
            "  Training Loss: 0.0011662624672641897, Training Accuracy: 1.0\n",
            "  Validation Loss: 9.775144391710455e-08, Validation Accuracy: 1.0\n",
            "Epoch: 6\n",
            "  Training Loss: 1.0728812434024349e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.311298076345224e-07, Validation Accuracy: 1.0\n",
            "Epoch: 7\n",
            "  Training Loss: 1.442427308262495e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.549714827575599e-07, Validation Accuracy: 1.0\n",
            "Epoch: 8\n",
            "  Training Loss: 1.5973980893591033e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6331605117159144e-07, Validation Accuracy: 1.0\n",
            "Epoch: 9\n",
            "  Training Loss: 1.657002357546844e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6689231507882596e-07, Validation Accuracy: 1.0\n",
            "Epoch: 10\n",
            "  Training Loss: 1.6689230939448407e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6689231507882596e-07, Validation Accuracy: 1.0\n",
            "Epoch: 11\n",
            "  Training Loss: 1.6689231507882596e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6689231507882596e-07, Validation Accuracy: 1.0\n",
            "Epoch: 12\n",
            "  Training Loss: 1.668923104602982e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6570022900452842e-07, Validation Accuracy: 1.0\n",
            "Epoch: 13\n",
            "  Training Loss: 1.6570022900452842e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6570022900452842e-07, Validation Accuracy: 1.0\n",
            "Epoch: 14\n",
            "  Training Loss: 1.6450814186441675e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6331605117159144e-07, Validation Accuracy: 1.0\n",
            "Epoch: 15\n",
            "  Training Loss: 1.6331605792174742e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6212397646597765e-07, Validation Accuracy: 1.0\n",
            "Epoch: 16\n",
            "  Training Loss: 1.6212398783466143e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6212397646597765e-07, Validation Accuracy: 1.0\n",
            "Epoch: 17\n",
            "  Training Loss: 1.609318971418361e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6093190176036386e-07, Validation Accuracy: 1.0\n",
            "Epoch: 18\n",
            "  Training Loss: 1.5973981568606632e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.5854773529611066e-07, Validation Accuracy: 1.0\n",
            "Epoch: 19\n",
            "  Training Loss: 1.5854773636192476e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.5735564922181312e-07, Validation Accuracy: 1.0\n",
            "Epoch: 20\n",
            "  Training Loss: 1.5735565028762721e-07, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.5735564922181312e-07, Validation Accuracy: 1.0\n",
            "Elapsed time for MLP model: 0.13343617518742878 mins\n",
            "-----------------------Train CNN-------------------------\n",
            "Epoch: 1\n",
            "  Training Loss: 28.66060287952423, Training Accuracy: 0.3600000083446503\n",
            "  Validation Loss: 1.5706932807329395, Validation Accuracy: 0.9199999928474426\n",
            "Epoch: 2\n",
            "  Training Loss: 0.5159091290400621, Training Accuracy: 0.9799999952316284\n",
            "  Validation Loss: 0.22450443521465502, Validation Accuracy: 0.9599999904632568\n",
            "Epoch: 3\n",
            "  Training Loss: 0.4437538101097857, Training Accuracy: 0.9299999892711639\n",
            "  Validation Loss: 0.7837154187227583, Validation Accuracy: 0.9599999904632568\n",
            "Epoch: 4\n",
            "  Training Loss: 1.000357786625281, Training Accuracy: 0.9399999916553498\n",
            "  Validation Loss: 0.2835017702312307, Validation Accuracy: 0.9699999928474426\n",
            "Epoch: 5\n",
            "  Training Loss: 0.15168255711244, Training Accuracy: 0.9899999976158143\n",
            "  Validation Loss: 9.358219685964286e-05, Validation Accuracy: 1.0\n",
            "Epoch: 6\n",
            "  Training Loss: 0.0022483891126466203, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.6569956180489952e-07, Validation Accuracy: 1.0\n",
            "Epoch: 7\n",
            "  Training Loss: 1.3113014674104306e-08, Training Accuracy: 1.0\n",
            "  Validation Loss: 1.0728831156825436e-08, Validation Accuracy: 1.0\n",
            "Epoch: 8\n",
            "  Training Loss: 1.0728831156825436e-08, Training Accuracy: 1.0\n",
            "  Validation Loss: 4.768370942542788e-09, Validation Accuracy: 1.0\n",
            "Epoch: 9\n",
            "  Training Loss: 4.768370942542788e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 4.768370942542788e-09, Validation Accuracy: 1.0\n",
            "Epoch: 10\n",
            "  Training Loss: 4.768370942542788e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 4.768370942542788e-09, Validation Accuracy: 1.0\n",
            "Epoch: 11\n",
            "  Training Loss: 4.768370942542788e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 4.768370942542788e-09, Validation Accuracy: 1.0\n",
            "Epoch: 12\n",
            "  Training Loss: 4.768370942542788e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 13\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 14\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 15\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 16\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 17\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 18\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 19\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Epoch: 20\n",
            "  Training Loss: 3.5762782957249327e-09, Training Accuracy: 1.0\n",
            "  Validation Loss: 3.5762782957249327e-09, Validation Accuracy: 1.0\n",
            "Elapsed time for CNN model: 0.21456197500228882 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGWEmoMEMeF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}